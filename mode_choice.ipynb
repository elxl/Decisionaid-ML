{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee701bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cc23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24710348",
   "metadata": {},
   "source": [
    "## Select feature and encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdc01d",
   "metadata": {},
   "source": [
    "Choice of features are chosen based on correlation and our understanding of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b96401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11481\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "# covert categorial features into one-hot encoding\n",
    "selected_features = [\n",
    "     'travel_date_dow',\n",
    "     'o_purpose_category',\n",
    "     'd_purpose_category',\n",
    "#      'num_non_hh_travelers',\n",
    "     'num_hh_travelers',\n",
    "     'num_travelers',\n",
    "#      'o_location_type',\n",
    "#      'd_location_type',\n",
    "     'o_congestion',\n",
    "     'd_congestion',\n",
    "#      'age',\n",
    "#      'employment',\n",
    "#      'student',\n",
    "     'license',\n",
    "#      'planning_apps',\n",
    "     'industry',\n",
    "#      'gender',\n",
    "#      'education',\n",
    "#      'survey_language',\n",
    "     'num_bicycles',\n",
    "     'num_vehicles',\n",
    "     'res_type',\n",
    "#      'rent_own',\n",
    "     'income_aggregate',\n",
    "#      'num_people',\n",
    "#      'num_adults',\n",
    "#      'num_kids',\n",
    "#      'num_workers',\n",
    "#      'num_students',\n",
    "     'disability',\n",
    "     'trip_distance_category'\n",
    "]\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "df_selected.loc[:,'trip_distance_category'] = df_selected['trip_distance_category'].replace({\"short\":0, \"medium\":1, \"long\":2})\n",
    "\n",
    "categorial_columns = ['travel_date_dow',\n",
    "       'o_purpose_category', 'd_purpose_category', 'o_location_type',\n",
    "       'd_location_type', 'age', 'employment', 'license', 'planning_apps', 'industry', 'gender'\n",
    "                    , 'survey_language',\n",
    "       'res_type', 'rent_own',  'disability']\n",
    "\n",
    "onehot = pd.get_dummies(df_selected, columns=[x for x in categorial_columns if x in selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e77e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['drive', 'passenger', 'bus', 'subway', 'bike', 'walk', 'other'])\n",
    "\n",
    "\n",
    "# Transfer string\n",
    "str_to_val = {\n",
    "    'drive': 0,\n",
    "    'passenger': 1,\n",
    "    'bus': 2,\n",
    "    'subway': 3,\n",
    "    'bike': 4,\n",
    "    'walk': 5,\n",
    "    'other': 6,\n",
    "}\n",
    "\n",
    "y = df['mode'].replace(str_to_val).to_numpy()\n",
    "X = onehot.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3d4bf",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e97d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import log_loss,confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "groups = df['person_id']\n",
    "group_kfold = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f343a2",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d5bf0",
   "metadata": {},
   "source": [
    "The range of parameters tried is partially taken from [this link](https://kevinvecmanis.io/machine%20learning/hyperparameter%20tuning/dataviz/python/2019/05/11/XGBoost-Tuning-Visual-Guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ca5cb",
   "metadata": {},
   "source": [
    "### hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe956e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbo = xgb.XGBClassifier(n_jobs=-1, random_state=42, objective=\"multi:softprob\", eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "distributions = {'n_estimators': np.arange(10,50,10), \n",
    "                 'max_depth': np.arange(5,20,1),\n",
    "                 'learning_rate': np.arange(0.0005,0.3,0.0005)}\n",
    "\n",
    "lr_xgbo = RandomizedSearchCV(xgbo, distributions, random_state=0, scoring = \"neg_log_loss\", n_iter = 10, cv=group_kfold)\n",
    "\n",
    "search_xgbo = lr_xgbo.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321f5b3",
   "metadata": {},
   "source": [
    "### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e6f3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = search_xgbo.best_estimator_\n",
    "best_score = search_xgbo.best_score_\n",
    "best_param = search_xgbo.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09420384",
   "metadata": {},
   "source": [
    "Define performance evaluation function for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97f200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_performance(best_estimator):\n",
    "    for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "        X_train, X_validate = X[train_index], X[validate_index]\n",
    "        y_train, y_validate = y[train_index], y[validate_index]\n",
    "        \n",
    "        # loss and accuracy\n",
    "        loss = []\n",
    "        acc = []\n",
    "\n",
    "        best_estimator.fit(X_train, y_train)\n",
    "        \n",
    "        proba_train = best_estimator.predict_proba(X_train)\n",
    "        proba_val = best_estimator.predict_proba(X_validate)\n",
    "        \n",
    "        loss_train = log_loss(y_train, proba_train)\n",
    "        loss_val = log_loss(y_validate, proba_val)\n",
    "        loss.append(loss_val)\n",
    "        \n",
    "        acc_train = accuracy_score(y_train, best_estimator.predict(X_train))\n",
    "        acc_val = accuracy_score(y_validate, best_estimator.predict(X_validate))\n",
    "        acc.append(acc_val)\n",
    "        \n",
    "        print(f\"training loss:{loss_train}\\t validating loss:{loss_val}\")\n",
    "\n",
    "        print(f\"training accuracy:{acc_train}\\t validating accuracy:{acc_val}\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        print('Confusion matrix:')\n",
    "        display(confusion_matrix(y_validate, best_estimator.predict(X_validate)))\n",
    "    \n",
    "    print(f\"loss:{np.mean(loss)}\\t accuracy:{np.mean(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a9a890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 40, 'max_depth': 5, 'learning_rate': 0.1775}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c20ac3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.8005575378485186\t validating loss:0.9092358116035468\n",
      "training accuracy:0.714847092378387\t validating accuracy:0.6613005450627456\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1873,   21,    9,   86,    1,  408,    1],\n",
       "       [ 488,  111,    2,   13,    0,  123,    1],\n",
       "       [  52,   20,   32,  141,    1,  184,    0],\n",
       "       [ 132,   49,   27,  531,    1,  242,    0],\n",
       "       [  12,   10,    0,   47,    2,   57,    0],\n",
       "       [ 236,   47,   15,   97,    3, 2667,    1],\n",
       "       [  18,   19,    1,   42,    0,   65,    1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.8029525680026839\t validating loss:0.9357357819966375\n",
      "training accuracy:0.710695610838219\t validating accuracy:0.6723285587526936\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1683,   77,    4,   72,    1,  298,   28],\n",
       "       [ 235,  163,    6,   12,    0,   97,    0],\n",
       "       [  65,   38,   39,  118,    0,  188,    0],\n",
       "       [ 109,   49,   37,  583,    0,  267,    0],\n",
       "       [  20,    7,    1,   43,    2,   75,    0],\n",
       "       [ 340,   42,   20,  101,    0, 2831,    1],\n",
       "       [ 122,   26,    2,   38,    0,   46,    3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.7930538069004657\t validating loss:0.9265771156578542\n",
      "training accuracy:0.7171288226905403\t validating accuracy:0.6779059449866903\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1834,   56,    6,   86,    1,  430,   11],\n",
       "       [ 261,  183,    6,   19,    0,  139,    1],\n",
       "       [  64,   38,   39,  151,    1,  196,    0],\n",
       "       [ 125,   47,   31,  559,    0,  249,    0],\n",
       "       [  12,    0,    0,    6,    1,   57,    1],\n",
       "       [ 216,   38,    9,  106,    2, 2731,    1],\n",
       "       [  47,   27,    6,   60,    0,   35,    1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.778716409909066\t validating loss:1.0358064133900096\n",
      "training accuracy:0.7206147995563302\t validating accuracy:0.6463430092533908\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1691,   85,    5,   88,    3,  423,    2],\n",
       "       [ 224,  186,    5,   18,    0,  107,    0],\n",
       "       [  79,   27,   49,  154,    0,  211,    1],\n",
       "       [ 130,   32,   43,  557,    3,  271,    2],\n",
       "       [  34,    0,    2,   35,    0,  147,    0],\n",
       "       [ 245,   57,   14,   98,    1, 2616,    0],\n",
       "       [  91,   20,    4,   57,    0,   72,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.797030219192868\t validating loss:0.9418681305984288\n",
      "training accuracy:0.7151730257320319\t validating accuracy:0.6724137931034483\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1822,   74,    6,  127,    1,  354,    2],\n",
       "       [ 290,  179,    1,   12,    0,  125,    0],\n",
       "       [  61,   26,   58,  123,    0,  179,    1],\n",
       "       [ 160,   39,   45,  507,    7,  192,    1],\n",
       "       [  24,    7,    0,   53,    5,   42,    0],\n",
       "       [ 279,   32,   15,   93,   10, 2733,    2],\n",
       "       [  61,   19,    4,   30,    1,   86,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.9418681305984288\t accuracy:0.6724137931034483\n"
     ]
    }
   ],
   "source": [
    "classifier_performance(best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27473ed",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7316c",
   "metadata": {},
   "source": [
    "### hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "260cfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "distributions = {\"n_estimators\": randint(low=10,high=100),\n",
    "                 \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"max_depth\": randint(low=10,high=20),\n",
    "                \"min_samples_leaf\": randint(low=5,high=100)}\n",
    "\n",
    "\n",
    "lr_rf = RandomizedSearchCV(rf, distributions, random_state=0, scoring = \"neg_log_loss\", n_iter = 50, cv=group_kfold)\n",
    "\n",
    "search_rf = lr_rf.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfbd32",
   "metadata": {},
   "source": [
    "### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06beb440",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = search_rf.best_estimator_\n",
    "best_score = search_rf.best_score_\n",
    "best_param = search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a841499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 18,\n",
       " 'min_samples_leaf': 6,\n",
       " 'n_estimators': 75}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc9aae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.7321596664889587\t validating loss:0.9445053341850436\n",
      "training accuracy:0.7382982094755189\t validating accuracy:0.6647230320699709\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1889,   10,    0,   87,    0,  413,    0],\n",
       "       [ 500,   87,    0,   20,    0,  131,    0],\n",
       "       [  68,   16,   12,  153,    0,  181,    0],\n",
       "       [ 139,   25,   10,  569,    0,  239,    0],\n",
       "       [  14,    6,    0,   46,    0,   62,    0],\n",
       "       [ 250,   22,    4,  103,    0, 2687,    0],\n",
       "       [  30,   10,    1,   39,    0,   66,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.7281890941282304\t validating loss:0.9557127195165052\n",
      "training accuracy:0.7389954048486769\t validating accuracy:0.6791735327671441\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1755,   43,    3,   74,    0,  285,    3],\n",
       "       [ 257,  128,    1,   18,    0,  109,    0],\n",
       "       [  72,   24,   18,  132,    0,  202,    0],\n",
       "       [ 115,   39,   10,  602,    0,  279,    0],\n",
       "       [  26,    7,    0,   40,    2,   73,    0],\n",
       "       [ 331,   30,    4,  116,    0, 2853,    1],\n",
       "       [ 136,    9,    0,   42,    0,   50,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.7247329477902607\t validating loss:0.9500746423658423\n",
      "training accuracy:0.7415623514498495\t validating accuracy:0.6756242869818735\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1875,   21,    0,   79,    0,  445,    4],\n",
       "       [ 290,  123,    1,   27,    0,  168,    0],\n",
       "       [  74,   21,   10,  175,    0,  209,    0],\n",
       "       [ 132,   19,   12,  583,    0,  265,    0],\n",
       "       [  12,    0,    0,    6,    0,   59,    0],\n",
       "       [ 233,   14,    3,  114,    0, 2739,    0],\n",
       "       [  55,   12,    1,   63,    0,   45,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.7134106104666947\t validating loss:1.0584109383469869\n",
      "training accuracy:0.7466011725558549\t validating accuracy:0.6505260489288883\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1736,   59,    1,   93,    0,  408,    0],\n",
       "       [ 240,  153,    2,   27,    0,  118,    0],\n",
       "       [  95,   24,    8,  194,    0,  200,    0],\n",
       "       [ 135,   21,    5,  615,    1,  261,    0],\n",
       "       [  39,    0,    0,   35,    0,  144,    0],\n",
       "       [ 262,   30,    2,  117,    0, 2620,    0],\n",
       "       [  93,   16,    2,   58,    0,   75,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.7275434453560324\t validating loss:0.9685817928134446\n",
      "training accuracy:0.739890987450881\t validating accuracy:0.678498985801217\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1905,   32,    2,  110,    0,  337,    0],\n",
       "       [ 307,  144,    0,    8,    0,  148,    0],\n",
       "       [  66,   15,   11,  153,    0,  203,    0],\n",
       "       [ 174,   30,   11,  536,    4,  196,    0],\n",
       "       [  25,    6,    0,   36,    9,   54,    1],\n",
       "       [ 280,   19,    5,  111,    2, 2747,    0],\n",
       "       [  70,    6,    0,   34,    0,   91,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.9685817928134446\t accuracy:0.678498985801217\n"
     ]
    }
   ],
   "source": [
    "classifier_performance(best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f43a2c",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a785fe67",
   "metadata": {},
   "source": [
    "Try decisiontree and svm as base classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93fd25",
   "metadata": {},
   "source": [
    "### hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "bag = BaggingClassifier(random_state=42)\n",
    "\n",
    "distributions = {\n",
    "    \"base_estimator\": [DecisionTreeClassifier(),SVC()],\n",
    "    \"n_estimators\": np.arange(10,100,10),\n",
    "    \"max_samples\": np.arange(0.1,1.0,0.1),\n",
    "    \"max_features\": np.arange(5,15)\n",
    "}\n",
    "\n",
    "lr_bag = RandomizedSearchCV(bag, distributions, random_state=0,  scoring = \"neg_log_loss\", n_iter = 10, cv=group_kfold)\n",
    "\n",
    "search_bag = lr_bag.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070aaf9a",
   "metadata": {},
   "source": [
    "### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = search_rf.best_estimator_\n",
    "best_score = search_rf.best_score_\n",
    "best_param = search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea146e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_performance(best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40063503",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37550382",
   "metadata": {},
   "source": [
    "Naive bayes has no parameters to tune, so we just try it with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405137a6",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13e10898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:17.485942507541232\t validating loss:18.1379970980222\n",
      "training accuracy:0.12492473459039771\t validating accuracy:0.10229433388262137\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 363,   36,   23,    5, 1570,   18,  384],\n",
       "       [  75,   19,    5,    6,  505,   11,  117],\n",
       "       [  31,    3,   18,   28,  300,    9,   41],\n",
       "       [  12,    3,   14,   80,  764,   21,   88],\n",
       "       [   0,    0,    0,   10,  111,    6,    1],\n",
       "       [  80,   23,   48,  107, 2429,  185,  194],\n",
       "       [  12,    3,    1,    6,   87,    6,   31]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:19.850054294354518\t validating loss:20.513092865587502\n",
      "training accuracy:0.08128664237046426\t validating accuracy:0.0759285080491824\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  90,  148,   22,   23, 1243,   27,  610],\n",
       "       [   8,   79,   17,    6,  290,   16,   97],\n",
       "       [   3,   11,   14,   24,  279,    5,  112],\n",
       "       [   4,    8,   19,   59,  758,    5,  192],\n",
       "       [   2,    0,    0,    5,  118,    0,   23],\n",
       "       [  22,   79,   41,   89, 2576,  106,  422],\n",
       "       [   0,    2,    3,   10,   87,    2,  133]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:17.904354892957322\t validating loss:19.496134453009095\n",
      "training accuracy:0.11608302963080336\t validating accuracy:0.0872100392952212\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 326,   91,   71,   28, 1523,  103,  282],\n",
       "       [  42,   31,   49,    4,  414,   15,   54],\n",
       "       [   3,    4,   66,   22,  342,   13,   39],\n",
       "       [   9,    2,   74,   50,  796,   17,   63],\n",
       "       [   4,    0,    0,    1,   53,   16,    3],\n",
       "       [  85,   40,  196,   45, 2473,  140,  124],\n",
       "       [   6,    8,   12,    5,  122,    1,   22]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:19.477417773644916\t validating loss:19.603181415183315\n",
      "training accuracy:0.10591031532245286\t validating accuracy:0.11243503612625175\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 306,  234,   57,   53, 1385,   54,  208],\n",
       "       [  49,   81,    8,   19,  335,    8,   40],\n",
       "       [  19,    6,   27,   17,  348,    8,   96],\n",
       "       [  15,    8,   48,  119,  764,   19,   65],\n",
       "       [   7,   10,    4,   11,  175,    6,    5],\n",
       "       [  63,  110,   92,  116, 2258,  159,  233],\n",
       "       [   5,    5,    7,    5,  201,    1,   20]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:18.536038087528713\t validating loss:18.847581331060834\n",
      "training accuracy:0.0765623019394093\t validating accuracy:0.057682555780933065\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 163,   47,   32,   12, 1558,    8,  566],\n",
       "       [  16,   19,   28,    1,  386,    1,  156],\n",
       "       [   7,    4,   39,    8,  253,   10,  127],\n",
       "       [   2,    1,   49,   46,  586,    3,  264],\n",
       "       [   1,    0,    2,    0,  100,    0,   28],\n",
       "       [  23,   16,  128,   61, 2338,   30,  568],\n",
       "       [   1,    2,   21,    3,  114,    2,   58]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:18.847581331060834\t accuracy:0.057682555780933065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_validate = X[train_index], X[validate_index]\n",
    "    y_train, y_validate = y[train_index], y[validate_index]\n",
    "\n",
    "    # loss and accuracy\n",
    "    loss = []\n",
    "    acc = []\n",
    "    \n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    proba_train = gnb.predict_proba(X_train)\n",
    "    proba_val = gnb.predict_proba(X_validate)\n",
    "\n",
    "    loss_train = log_loss(y_train, proba_train)\n",
    "    loss_val = log_loss(y_validate, proba_val)\n",
    "    loss.append(loss_val)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, gnb.predict(X_train))\n",
    "    acc_val = accuracy_score(y_validate, gnb.predict(X_validate))\n",
    "    acc.append(acc_val)\n",
    "\n",
    "    print(f\"training loss:{loss_train}\\t validating loss:{loss_val}\")\n",
    "\n",
    "    print(f\"training accuracy:{acc_train}\\t validating accuracy:{acc_val}\")\n",
    "        \n",
    "    # Confusion matrix\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix(y_validate, gnb.predict(X_validate)))\n",
    "\n",
    "print(f\"loss:{np.mean(loss)}\\t accuracy:{np.mean(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8164c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_performance(gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399651fe",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d0236",
   "metadata": {},
   "source": [
    "We don't use cross validation for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# train-validation split\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=2, train_size=.75, random_state=42)\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    X_train, X_validate = X[train_idx,:], X[test_idx,:]\n",
    "    y_train, y_validate = y[train_idx], y[test_idx]\n",
    "\n",
    "parameters = {'learning_rate_init':[1e-4,1e-3,1e-2],\n",
    "              'learning_rate':['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "ann = MLPClassifier(activation = 'relu', solver = 'adam', max_iter=300, random_state=42)\n",
    "\n",
    "lr_ann = RandomizedSearchCV(bag, parameters, random_state=0,  scoring = \"neg_log_loss\")\n",
    "search_ann = lr_ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6a96924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11481\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:0.28482676340049695\t validating loss:3.191636463283548\n",
      "training accuracy:0.8999590974163202\t validating accuracy:0.5422521274490402\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2278,   17,    3,  108,    0,  320,    1],\n",
       "       [ 296,  353,    0,   12,    0,  155,    0],\n",
       "       [  79,   21,   68,  174,    0,  268,    0],\n",
       "       [ 193,   26,    6,  837,    1,  262,    0],\n",
       "       [  19,    2,    1,   43,   13,  132,    0],\n",
       "       [ 260,   18,   10,  115,    0, 3708,    0],\n",
       "       [  88,    9,    1,   62,    0,   94,   53]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try one scenario\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(100,50,20), activation = 'relu', solver = 'adam', alpha = 1e-5, learning_rate= 'adaptive', learning_rate_init = 1e-3, max_iter=300, random_state=42)\n",
    "ann.fit(X_train,y_train)\n",
    "\n",
    "proba_train = ann.predict_proba(X_train)\n",
    "proba_val = ann.predict_proba(X_validate)\n",
    "\n",
    "loss_train = log_loss(y_train, proba_train)\n",
    "loss_val = log_loss(y_validate, proba_val)\n",
    "\n",
    "acc_train = accuracy_score(y_train, ann.predict(X_train))\n",
    "acc_val = accuracy_score(y_validate, ann.predict(X_validate))\n",
    "\n",
    "print(f\"training loss:{loss_train}\\t validating loss:{loss_val}\")\n",
    "\n",
    "print(f\"training accuracy:{acc_train}\\t validating accuracy:{acc_val}\")\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix(y_validate, best_estimator.predict(X_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce23653",
   "metadata": {},
   "source": [
    "### Train the best model with the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_estimator.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
