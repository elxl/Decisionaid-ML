{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee701bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cc23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24710348",
   "metadata": {},
   "source": [
    "## Select feature and encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f840a51",
   "metadata": {},
   "source": [
    "Choice of features are chosen based on correlation and our understanding of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b96401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert categorial features into one-hot encoding\n",
    "selected_features = [\n",
    "     'travel_date_dow',\n",
    "     'o_purpose_category',\n",
    "     'd_purpose_category',\n",
    "#      'num_non_hh_travelers',\n",
    "     'num_hh_travelers',\n",
    "     'num_travelers',\n",
    "#      'o_location_type',\n",
    "#      'd_location_type',\n",
    "     'o_congestion',\n",
    "     'd_congestion',\n",
    "#      'age',\n",
    "#      'employment',\n",
    "#      'student',\n",
    "     'license',\n",
    "#      'planning_apps',\n",
    "     'industry',\n",
    "#      'gender',\n",
    "#      'education',\n",
    "#      'survey_language',\n",
    "     'num_bicycles',\n",
    "     'num_vehicles',\n",
    "     'res_type',\n",
    "#      'rent_own',\n",
    "     'income_aggregate',\n",
    "#      'num_people',\n",
    "#      'num_adults',\n",
    "#      'num_kids',\n",
    "#      'num_workers',\n",
    "#      'num_students',\n",
    "     'disability',\n",
    "     'trip_distance'\n",
    "]\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "\n",
    "categorial_columns = ['travel_date_dow',\n",
    "       'o_purpose_category', 'd_purpose_category', 'o_location_type',\n",
    "       'd_location_type', 'age', 'employment', 'license', 'planning_apps', 'industry', 'gender'\n",
    "                    , 'survey_language',\n",
    "       'res_type', 'rent_own',  'disability']\n",
    "\n",
    "onehot = pd.get_dummies(df_selected, columns=[x for x in categorial_columns if x in selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e77e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['drive', 'passenger', 'bus', 'subway', 'bike', 'walk', 'other'])\n",
    "\n",
    "\n",
    "# Transfer string\n",
    "str_to_val = {\n",
    "    'drive': 0,\n",
    "    'passenger': 1,\n",
    "    'bus': 2,\n",
    "    'subway': 3,\n",
    "    'bike': 4,\n",
    "    'walk': 5,\n",
    "    'other': 6,\n",
    "}\n",
    "\n",
    "y = df['mode'].replace(str_to_val).to_numpy()\n",
    "X = onehot.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3d4bf",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-validation split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import log_loss,confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "groups = df['person_id']\n",
    "group_kfold = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565486e",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029ec9a6",
   "metadata": {},
   "source": [
    "The range of parameters tried is partially taken from [this link](https://kevinvecmanis.io/machine%20learning/hyperparameter%20tuning/dataviz/python/2019/05/11/XGBoost-Tuning-Visual-Guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ca5cb",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe956e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgbo = xgb.XGBClassifier(n_jobs=-1, random_state=42, objective=\"multi:softprob\", eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "distributions = {'n_estimators': np.arange(10,50,10), \n",
    "                 'max_depth': np.arange(5,20,1),\n",
    "                 'learning_rate': np.arange(0.0005,0.3,0.0005)}\n",
    "\n",
    "lr_xgbo = RandomizedSearchCV(xgbo, distributions, random_state=0, scoring = \"neg_log_loss\", n_iter = 10, cv=group_kfold)\n",
    "\n",
    "search_xgbo = lr_xgbo.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e16f0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss:0.9412916558006671\n",
      "accuracy:0.6673849664089239\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1873,   21,   18,  103,    3,  346,   35],\n",
       "       [ 458,  107,    4,   21,    1,   97,   50],\n",
       "       [  58,   21,   32,  162,    2,  154,    1],\n",
       "       [ 139,   36,   55,  567,    6,  178,    1],\n",
       "       [  14,    6,    0,   64,    1,   43,    0],\n",
       "       [ 217,   25,   31,  105,    3, 2682,    3],\n",
       "       [  27,   12,    6,   42,    1,   55,    3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss:0.9616968244548412\n",
      "accuracy:0.6776524274305996\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1634,   75,   11,   94,    3,  255,   91],\n",
       "       [ 244,  167,    8,   16,    0,   77,    1],\n",
       "       [  69,   28,   46,  126,    4,  172,    3],\n",
       "       [ 111,   54,   42,  634,    6,  193,    5],\n",
       "       [  22,    5,    3,   45,   17,   56,    0],\n",
       "       [ 314,   37,   49,   84,    1, 2840,   10],\n",
       "       [ 109,   37,    5,   35,    2,   41,    8]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss:0.9500715818630605\n",
      "accuracy:0.6865255418937761\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1856,   73,   13,  106,    8,  357,   11],\n",
       "       [ 271,  180,   10,   26,    1,  119,    2],\n",
       "       [  79,   33,   53,  158,    1,  163,    2],\n",
       "       [ 133,   32,   42,  612,    8,  181,    3],\n",
       "       [  12,    1,    5,    8,    5,   45,    1],\n",
       "       [ 222,   34,   28,  105,    4, 2707,    3],\n",
       "       [  46,   24,    5,   59,    0,   39,    3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss:1.0468883413709544\n",
      "accuracy:0.6559766763848397\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1691,   93,   22,  107,    4,  372,    8],\n",
       "       [ 214,  193,   15,   25,    0,   91,    2],\n",
       "       [  98,   27,   69,  161,    0,  162,    4],\n",
       "       [ 147,   29,   57,  601,    4,  194,    6],\n",
       "       [  40,    2,   10,   48,    1,  116,    1],\n",
       "       [ 240,   33,   23,  110,    2, 2619,    4],\n",
       "       [  90,   16,    8,   57,    0,   72,    1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss:0.9635069462268577\n",
      "accuracy:0.672920892494929\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1858,   78,   17,  142,    6,  282,    3],\n",
       "       [ 293,  189,    2,   17,    0,  104,    2],\n",
       "       [  70,   16,   47,  140,    0,  172,    3],\n",
       "       [ 178,   37,   53,  501,   15,  164,    3],\n",
       "       [  30,    9,    0,   39,   17,   32,    4],\n",
       "       [ 297,   29,   29,   94,   16, 2694,    5],\n",
       "       [  58,   16,    6,   30,    1,   88,    2]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss,confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = xgb.XGBClassifier(n_estimators = 30,  max_depth = 10,learning_rate = 0.1, n_jobs=-1, random_state=42, objective=\"multi:softprob\", eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "\n",
    "for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_validate = X[train_index], X[validate_index]\n",
    "    y_train, y_validate = y[train_index], y[validate_index]\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    proba = clf.predict_proba(X_validate)\n",
    "    loss = log_loss(y_validate, proba)\n",
    "    \n",
    "    print(f\"cross entropy loss:{loss}\")\n",
    "    \n",
    "    print(f\"accuracy:{accuracy_score(y_validate, clf.predict(X_validate))}\")\n",
    "    # Confusion matrix\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix(y_validate, clf.predict(X_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321f5b3",
   "metadata": {},
   "source": [
    "### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6f3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = search_xgbo.best_estimator_\n",
    "best_score = search_xgbo.best_score_\n",
    "best_param = search_xgbo.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f7871",
   "metadata": {},
   "source": [
    "Define performance evaluation function for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_performance(best_estimator):\n",
    "    for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "        X_train, X_validate = X[train_index], X[validate_index]\n",
    "        y_train, y_validate = y[train_index], y[validate_index]\n",
    "        \n",
    "        # loss and accuracy\n",
    "        loss = []\n",
    "        acc = []\n",
    "\n",
    "        best_estimator.fit(X_train, y_train)\n",
    "        \n",
    "        proba_train = best_estimator.predict_proba(X_train)\n",
    "        proba_val = best_estimator.predict_proba(X_validate)\n",
    "        \n",
    "        loss_train = log_loss(y_train, proba_train)\n",
    "        loss_val = log_loss(y_validate, proba_val)\n",
    "        loss.append(loss_val)\n",
    "        \n",
    "        acc_train = accuracy_score(y_train, best_estimator.predict(X_train))\n",
    "        acc_val = accuracy_score(y_validate, best_estimator.predict(X_validate))\n",
    "        acc.append(acc_val)\n",
    "        \n",
    "        print(f\"training loss:{loss_train}\\t validating loss:{loss_val}\")\n",
    "\n",
    "        print(f\"training accuracy:{acc_train}\\t validating accuracy:{acc_val}\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        print('Confusion matrix:')\n",
    "        display(confusion_matrix(y_validate, best_estimator.predict(X_validate)))\n",
    "    \n",
    "    print(f\"loss:{loss.mean()}\\t accuracy:acc.mean()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier_performance(best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d53e93",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26c1fa",
   "metadata": {},
   "source": [
    "Naive bayes has no parameters to tune, so we just try it with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feae033",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b34c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_validate = X[train_index], X[validate_index]\n",
    "    y_train, y_validate = y[train_index], y[validate_index]\n",
    "\n",
    "    # loss and accuracy\n",
    "    loss = []\n",
    "    acc = []\n",
    "    \n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    proba_train = gnb.predict_proba(X_train)\n",
    "    proba_val = gnb.predict_proba(X_validate)\n",
    "\n",
    "    loss_train = log_loss(y_train, proba_train)\n",
    "    loss_val = log_loss(y_validate, proba_val)\n",
    "    loss.append(loss_val)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, gnb.predict(X_train))\n",
    "    acc_val = accuracy_score(y_validate, gnb.predict(X_validate))\n",
    "    acc.append(acc_val)\n",
    "\n",
    "    print(f\"training loss:{loss_train}\\t validating loss:{loss_val}\")\n",
    "\n",
    "    print(f\"training accuracy:{acc_train}\\t validating accuracy:{acc_val}\")\n",
    "        \n",
    "    # Confusion matrix\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix(y_validate, clf.predict(X_validate)))\n",
    "\n",
    "print(f\"loss:{loss.mean()}\\t accuracy:acc.mean()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79870a11",
   "metadata": {},
   "source": [
    "### Train the best model with the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_estimator.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
