{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee701bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cc23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24710348",
   "metadata": {},
   "source": [
    "## Select feature and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b96401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert categorial features into one-hot encoding\n",
    "selected_features = [\n",
    "     'travel_date_dow',\n",
    "     'o_purpose_category',\n",
    "     'd_purpose_category',\n",
    "#      'num_non_hh_travelers',\n",
    "     'num_hh_travelers',\n",
    "     'num_travelers',\n",
    "#      'o_location_type',\n",
    "#      'd_location_type',\n",
    "     'o_congestion',\n",
    "     'd_congestion',\n",
    "#      'age',\n",
    "#      'employment',\n",
    "#      'student',\n",
    "     'license',\n",
    "#      'planning_apps',\n",
    "     'industry',\n",
    "#      'gender',\n",
    "#      'education',\n",
    "#      'survey_language',\n",
    "     'num_bicycles',\n",
    "     'num_vehicles',\n",
    "     'res_type',\n",
    "#      'rent_own',\n",
    "     'income_aggregate',\n",
    "#      'num_people',\n",
    "#      'num_adults',\n",
    "#      'num_kids',\n",
    "#      'num_workers',\n",
    "#      'num_students',\n",
    "     'disability',\n",
    "     'trip_distance'\n",
    "]\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "\n",
    "categorial_columns = ['travel_date_dow',\n",
    "       'o_purpose_category', 'd_purpose_category', 'o_location_type',\n",
    "       'd_location_type', 'age', 'employment', 'license', 'planning_apps', 'industry', 'gender'\n",
    "                    , 'survey_language',\n",
    "       'res_type', 'rent_own',  'disability']\n",
    "\n",
    "onehot = pd.get_dummies(df_selected, columns=[x for x in categorial_columns if x in selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e77e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['drive', 'passenger', 'bus', 'subway', 'bike', 'walk', 'other'])\n",
    "\n",
    "\n",
    "# Transfer string\n",
    "str_to_val = {\n",
    "    'drive':0,\n",
    "    'passenger': 1,\n",
    "    'bus': 2,\n",
    "    'subway': 3,\n",
    "    'bike': 4,\n",
    "    'walk': 5,\n",
    "    'other': 6,\n",
    "}\n",
    "\n",
    "y = df['mode'].replace(str_to_val).to_numpy()\n",
    "X = onehot.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3d4bf",
   "metadata": {},
   "source": [
    "## Tune parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ca5cb",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4c9b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0\n",
       "         ... \n",
       "39439    1794\n",
       "39440    1794\n",
       "39441    1794\n",
       "39442    1794\n",
       "39443    1794\n",
       "Name: person_id, Length: 39444, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "groups = df['person_id']\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90afd50",
   "metadata": {},
   "source": [
    "## RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe956e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "#dictionary of parameters to perform hyperparameters search:\n",
    "param_distribution = {\n",
    "    #\"n_estimators\": randint(low=1,high=10),\n",
    "    #\"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": randint(low=10,high=20),\n",
    "    #\"min_samples_split\": randint(low=1,high=10),\n",
    "    #\"min_samples_leaf\": randint(low=1,high=10)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "paramSearch = RandomizedSearchCV(RF,param_distributions=param_distribution,  scoring = \"neg_log_loss\", n_iter = 10, cv=group_kfold)\n",
    "\n",
    "\n",
    "#logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=0)\n",
    "\n",
    "#distributions = dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'])\n",
    "\n",
    "#lr = RandomizedSearchCV(logistic, distributions, random_state=0, scoring = \"neg_log_loss\", n_iter = 10)\n",
    "\n",
    "search = paramSearch.fit(X, y, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321f5b3",
   "metadata": {},
   "source": [
    "### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e6f3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = search.best_estimator_\n",
    "best_score = search.best_score_\n",
    "best_param = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c97f200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:0.6763848396501457\n",
      "accuracy on train set:0.8619236254159405\n",
      "cross entropy loss:0.9172347639555577\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1908,   12,    3,  113,    0,  363,    0],\n",
       "       [ 510,  103,    0,   22,    0,  103,    0],\n",
       "       [  69,   19,   22,  159,    0,  161,    0],\n",
       "       [ 134,   33,   21,  602,    0,  191,    1],\n",
       "       [  13,    7,    0,   63,    0,   45,    0],\n",
       "       [ 243,   16,   11,   94,    1, 2701,    0],\n",
       "       [  30,   11,    6,   44,    0,   55,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n",
      "accuracy on validate set:0.6959056914691343\n",
      "accuracy on train set:0.8631595626683568\n",
      "cross entropy loss:0.9354572770821021\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1761,   47,    5,   85,    0,  259,    6],\n",
       "       [ 262,  149,    2,   15,    0,   85,    0],\n",
       "       [  75,   28,   19,  138,    0,  188,    0],\n",
       "       [ 112,   51,   23,  658,    0,  201,    0],\n",
       "       [  21,    7,    0,   48,    9,   63,    0],\n",
       "       [ 309,   29,    9,   92,    1, 2894,    1],\n",
       "       [ 136,   13,    1,   39,    0,   48,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n",
      "accuracy on validate set:0.691469134237546\n",
      "accuracy on train set:0.8651560766914911\n",
      "cross entropy loss:0.9321803402627333\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1878,   45,    6,  111,    1,  379,    4],\n",
       "       [ 290,  155,    2,   26,    0,  136,    0],\n",
       "       [  74,   23,   26,  183,    0,  183,    0],\n",
       "       [ 136,   33,   13,  628,    2,  199,    0],\n",
       "       [  14,    1,    0,   11,    1,   50,    0],\n",
       "       [ 218,   12,    9,   97,    0, 2767,    0],\n",
       "       [  52,   15,    1,   64,    0,   44,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n",
      "accuracy on validate set:0.661427303840791\n",
      "accuracy on train set:0.8707970210743147\n",
      "cross entropy loss:1.046976609803078\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1724,   55,   10,  114,    0,  394,    0],\n",
       "       [ 242,  173,    3,   23,    1,   98,    0],\n",
       "       [  89,   31,   22,  203,    0,  176,    0],\n",
       "       [ 141,   29,   17,  632,    1,  218,    0],\n",
       "       [  48,    0,    7,   50,    0,  113,    0],\n",
       "       [ 223,   30,    7,  104,    0, 2667,    0],\n",
       "       [  94,   15,    1,   60,    0,   74,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n",
      "accuracy on validate set:0.6847109533468559\n",
      "accuracy on train set:0.865952592217011\n",
      "cross entropy loss:0.9508344421820869\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1889,   43,    3,  125,    1,  324,    1],\n",
       "       [ 307,  165,    0,   15,    0,  120,    0],\n",
       "       [  65,   22,   20,  140,    0,  201,    0],\n",
       "       [ 166,   35,   14,  552,    4,  180,    0],\n",
       "       [  26,    6,    0,   42,   15,   42,    0],\n",
       "       [ 279,   21,    9,   96,    6, 2753,    0],\n",
       "       [  64,   10,    3,   35,    0,   82,    7]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_validate = X[train_index], X[validate_index]\n",
    "    y_train, y_validate = y[train_index], y[validate_index]\n",
    "    \n",
    "    \n",
    "    best_estimator.fit(X_train, y_train)\n",
    "    proba = best_estimator.predict_proba(X_validate)\n",
    "    loss = log_loss(y_validate, proba)\n",
    "    acc_validate = accuracy_score(y_validate,best_estimator.predict(X_validate))\n",
    "    acc_train = accuracy_score(y_train,best_estimator.predict(X_train))\n",
    "    \n",
    "    #Accuracy score:\n",
    "    print(f\"accuracy on validate set:{acc_validate}\")\n",
    "    print(f\"accuracy on train set:{acc_train}\")\n",
    "    \n",
    "    #Entropoy loss score: \n",
    "    print(f\"cross entropy loss:{loss}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix(y_validate, best_estimator.predict(X_validate)))\n",
    "    \n",
    "    print(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea0c3143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=8, n_estimators=7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef87f8",
   "metadata": {},
   "source": [
    "## BaggingClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b723be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanalevkov/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "BAG = BaggingClassifier()\n",
    "\n",
    "#dictionary of parameters to perform hyperparameters search:\n",
    "param_distribution = {\n",
    "    \"base_estimator\": [DecisionTreeClassifier(),SVC()],\n",
    "    #\"n_estimators\": [5,10],\n",
    "    #\"max_samples\": [1,5],\n",
    "    #\"max_features\": [5,15],\n",
    "    #\"warm_start\": [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "paramSearch = RandomizedSearchCV(BAG,param_distributions=param_distribution,  scoring = \"neg_log_loss\", n_iter = 10, cv=group_kfold)\n",
    "\n",
    "\n",
    "\n",
    "search = paramSearch.fit(X, y, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11072b40",
   "metadata": {},
   "source": [
    "### Performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = search.best_estimator_\n",
    "best_score = search.best_score_\n",
    "best_param = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "for train_index, validate_index in group_kfold.split(X, y, groups):\n",
    "    X_train, X_validate = X[train_index], X[validate_index]\n",
    "    y_train, y_validate = y[train_index], y[validate_index]\n",
    "    \n",
    "    \n",
    "    best_estimator.fit(X_train, y_train)\n",
    "    proba = best_estimator.predict_proba(X_validate)\n",
    "    loss = log_loss(y_validate, proba)\n",
    "    acc_validate = accuracy_score(y_validate,best_estimator.predict(X_validate))\n",
    "    acc_train = accuracy_score(y_train,best_estimator.predict(X_train))\n",
    "    \n",
    "    #Accuracy score:\n",
    "    print(f\"accuracy on validate set:{acc_validate}\")\n",
    "    print(f\"accuracy on train set:{acc_train}\")\n",
    "    \n",
    "    #Entropoy loss score: \n",
    "    print(f\"cross entropy loss:{loss}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print('Confusion matrix:')\n",
    "    display(confusion_matrix(y_validate, best_estimator.predict(X_validate)))\n",
    "    \n",
    "    print(best_param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
